{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Optimizer Demo\n",
    "\n",
    "This single-cell demo analyzes a pasted SQL query, suggests indexes, provides heuristic rewrites, and optionally runs `EXPLAIN QUERY PLAN` if you upload CSV/DDL files. Run each cell in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sql-optimizer-main-cell",
    "outputId": "output"
   },
   "outputs": [],
   "source": [
    "# One-cell SQL Optimizer Demo (Colab)\n",
    "# Paste this cell into Google Colab and run. Upload CSV/DDL files if you want EXPLAIN support.\n",
    "\n",
    "try:\n",
    "    # Colab / Notebook installs\n",
    "    import sys\n",
    "    !pip -q install sqlparse sql_metadata sqlglot openai pandas\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import sqlparse, os, re, json\n",
    "from sql_metadata import Parser\n",
    "import sqlglot\n",
    "from google.colab import files\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def print_h1(s):\n",
    "    print('\\n' + '='*len(s))\n",
    "    print(s)\n",
    "    print('='*len(s) + '\\n')\n",
    "\n",
    "print_h1('STEP 1 — Paste SQL (end with empty line)')\n",
    "print('Paste your SQL (multi-line). Press Enter twice to finish:')\n",
    "lines = []\n",
    "while True:\n",
    "    try:\n",
    "        l = input()\n",
    "    except EOFError:\n",
    "        break\n",
    "    if l.strip()=='' and len(lines)>0:\n",
    "        break\n",
    "    lines.append(l)\n",
    "user_sql = '\\n'.join(lines).strip()\n",
    "if not user_sql:\n",
    "    print('No SQL provided — exiting.')\n",
    "    raise SystemExit\n",
    "\n",
    "print_h1('Formatted SQL')\n",
    "print(sqlparse.format(user_sql, reindent=True, keyword_case='upper'))\n",
    "\n",
    "print_h1('Parsing query structure')\n",
    "try:\n",
    "    parser = Parser(user_sql)\n",
    "    tables = parser.tables\n",
    "    columns = parser.columns\n",
    "    where_columns = parser.columns_dict.get('where', [])\n",
    "except Exception as e:\n",
    "    print('Parsing error:', e)\n",
    "    tables, columns, where_columns = [], [], []\n",
    "\n",
    "print('Tables detected:', tables)\n",
    "print('Columns detected (sample):', columns[:50])\n",
    "print('WHERE columns:', where_columns)\n",
    "\n",
    "print_h1('Heuristic suggestions & index recommendations')\n",
    "suggestions = []\n",
    "suggestions.append('Avoid SELECT * in production; list required columns to reduce IO.')\n",
    "suggestions.append('Use LIMIT for exploratory queries to avoid large result sets.')\n",
    "suggestions.append('Prefer explicit JOIN types and ensure join/filter columns are indexed.')\n",
    "\n",
    "# Build index recommendations heuristically\n",
    "index_recommendations = []\n",
    "filter_cols = set(where_columns)\n",
    "on_matches = re.findall(r\"ON\\s+([^\\n\\r]+?)(?:\\s+WHERE|\\s+JOIN|\\)|$)\", user_sql, flags=re.I)\n",
    "on_cols = []\n",
    "for m in on_matches:\n",
    "    on_cols += re.findall(r\"([A-Za-z_][A-Za-z0-9_]*\\.[A-Za-z_][A-Za-z0-9_]*)\", m)\n",
    "    on_cols += re.findall(r\"([A-Za-z_][A-Za-z0-9_]*)\\s*=\\s*[A-Za-z_][A-Za-z0-9_]*\", m)\n",
    "filter_cols.update([c.split('.')[-1] for c in on_cols if '.' in c] + on_cols)\n",
    "\n",
    "groupby_cols = []\n",
    "m = re.search(r\"GROUP\\s+BY\\s+([^\\n\\r]+?)(?:\\s+ORDER|\\s+HAVING|\\)|$)\", user_sql, flags=re.I)\n",
    "if m:\n",
    "    gb = re.split(r\",\\s*\", m.group(1).strip())\n",
    "    groupby_cols = [re.sub(r\"\\W\", \"\", g) for g in gb]\n",
    "\n",
    "for t in tables:\n",
    "    rec_cols = []\n",
    "    pref = []\n",
    "    for c in filter_cols:\n",
    "        if '.' in c and c.split('.')[0].lower() == t.lower():\n",
    "            pref.append(c.split('.')[-1])\n",
    "    rec_cols += pref\n",
    "    common_cols = [\"id\",\"user_id\",\"created_at\",\"updated_at\"]\n",
    "    for cc in common_cols:\n",
    "        if cc in columns and len(rec_cols)<3:\n",
    "            rec_cols.append(cc)\n",
    "    for g in groupby_cols:\n",
    "        if len(rec_cols)<3:\n",
    "            rec_cols.append(g)\n",
    "    for c in filter_cols:\n",
    "        if len(rec_cols)<3 and c in columns:\n",
    "            rec_cols.append(c)\n",
    "    if rec_cols:\n",
    "        index_recommendations.append({'table':t, 'columns':rec_cols[:3]})\n",
    "        suggestions.append(f\"Consider indexes on {t}({', '.join(rec_cols[:3])}) to speed WHERE and JOIN filters.\")\n",
    "\n",
    "for s in suggestions:\n",
    "    print('-', s)\n",
    "\n",
    "print_h1('Generated CREATE INDEX statements (heuristic)')\n",
    "for rec in index_recommendations:\n",
    "    cols = rec['columns']\n",
    "    stmt = f\"CREATE INDEX idx_{rec['table']}_{'_'.join(cols)} ON {rec['table']}({', '.join(cols)});\"\n",
    "    print(stmt)\n",
    "\n",
    "print_h1('Attempted rewrites (simple heuristics)')\n",
    "rewrites = []\n",
    "sel = re.search(r\"SELECT\\s+(.*?)\\s+FROM\", user_sql, flags=re.I|re.S)\n",
    "selected_cols = []\n",
    "if sel:\n",
    "    sel_cols = re.split(r\",\\s*\", sel.group(1).strip())\n",
    "    selected_cols = [re.sub(r\".*\\.\",\"\", re.sub(r\"\\W\", \"\", c)) for c in sel_cols if c.strip() != \"*\"]\n",
    "if '*' in user_sql and selected_cols:\n",
    "    explicit = ', '.join(selected_cols)\n",
    "    rewrites.append(('Replace SELECT * with explicit columns', re.sub(r\"SELECT\\s+\\*\", f\"SELECT {explicit}\", user_sql, flags=re.I)))\n",
    "if rewrites:\n",
    "    for title, q in rewrites:\n",
    "        print('->', title)\n",
    "        print(sqlparse.format(q, reindent=True, keyword_case='upper'))\n",
    "else:\n",
    "    print('No safe heuristic rewrites generated.')\n",
    "\n",
    "print_h1('Optional: Upload CSV/DDL files to run EXPLAIN (press Enter to skip)')\n",
    "print('Upload now (use the file upload dialog) or press Enter to skip:')\n",
    "up = files.upload()\n",
    "if up:\n",
    "    conn = sqlite3.connect('temp_db.sqlite')\n",
    "    for fname in up.keys():\n",
    "        print('Processing', fname)\n",
    "        if fname.lower().endswith('.csv'):\n",
    "            tname = os.path.splitext(os.path.basename(fname))[0]\n",
    "            df_csv = pd.read_csv(fname)\n",
    "            df_csv.to_sql(tname, conn, if_exists='replace', index=False)\n",
    "            print(f'Loaded {tname} rows={len(df_csv)}')\n",
    "        elif fname.lower().endswith('.sql'):\n",
    "            ddl = open(fname).read()\n",
    "            try:\n",
    "                conn.executescript(ddl)\n",
    "                print('Executed DDL')\n",
    "            except Exception as e:\n",
    "                print('DDL error', e)\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f'EXPLAIN QUERY PLAN {user_sql}')\n",
    "        rows = cur.fetchall()\n",
    "        print('\\nSQLite EXPLAIN QUERY PLAN:')\n",
    "        for r in rows:\n",
    "            print(r)\n",
    "    except Exception as e:\n",
    "        print('EXPLAIN failed:', e)\n",
    "\n",
    "print_h1('Final Report (saved)')\n",
    "report = {\n",
    "    'original_sql': user_sql,\n",
    "    'tables': tables,\n",
    "    'columns': columns[:200],\n",
    "    'suggestions': suggestions,\n",
    "    'index_recommendations': index_recommendations,\n",
    "    'rewrites': [q for _,q in rewrites]\n",
    "}\n",
    "plain = []\n",
    "plain.append('SQL Query Optimizer Report')\n",
    "plain.append('-'*40)\n",
    "plain.append('Original SQL:')\n",
    "plain.append(user_sql)\n",
    "plain.append('\\nDetected tables: ' + ', '.join(tables))\n",
    "plain.append('\\nSuggestions:')\n",
    "for s in suggestions:\n",
    "    plain.append('- ' + s)\n",
    "plain.append('\\nIndex recommendations:')\n",
    "for rec in index_recommendations:\n",
    "    cols = rec['columns']\n",
    "    plain.append(f\"- {rec['table']}({', '.join(cols)})\")\n",
    "plain_text = '\\n'.join(plain)\n",
    "with open('sql_optimizer_report.txt','w') as f:\n",
    "    f.write(plain_text)\n",
    "print('Saved report to sql_optimizer_report.txt')\n",
    "files.download('sql_optimizer_report.txt')\n",
    "if index_recommendations:\n",
    "    with open('suggested_indexes.sql','w') as f:\n",
    "        for rec in index_recommendations:\n",
    "            cols = rec['columns']\n",
    "            f.write(f\"CREATE INDEX idx_{rec['table']}_{'_'.join(cols)} ON {rec['table']}({', '.join(cols)});\\n\")\n",
    "    print('Saved suggested_indexes.sql')\n",
    "\n",
    "print('\\nDone. Use the generated suggestions in a staging environment before applying in production.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
